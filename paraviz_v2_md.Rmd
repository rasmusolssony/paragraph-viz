---
title: "Paragraph_Viz_V2_Exjobb_pipeline"
author: "Rasmus Olsson"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r setup, include=FALSE}
options(warn=1)
knitr::opts_chunk$set(echo = TRUE)

```

# Import packages and functions
```{r import the plotting functions, echo=TRUE}
library(text)
reticulate::source_python("fullStopCorrt.py")
reticulate::source_python("utils.py")
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding = localeToCharset()
)

options(future.globals.maxSize = 1.0 * 1e10)

```

# Select model, data and parameters
```{r data import, echo=TRUE}
#nameLLM <- "bert-base-uncased"
nameLLM <- "mixedbread-ai/mxbai-embed-large-v1"

text_set <- "Deptext"
scale_total <- "PHQtot" #for 1000 dataset

data <- read_csv("dataset.csv")

data <- data[, c(text_set, scale_total)]
data <- drop_na(data)
data_length <- nrow(data)
data[[text_set]] <- gsub("\\.(?![\\.\\s])", ". ", data[[text_set]], perl = TRUE)
# size of train and test sets
test_size <- 50
train_size <- data_length - test_size

model_folder_path <- paste0("models/", nameLLM, "-", text_set, "-", train_size, "-ridge") # nolint: line_length_linter.
embeddings_folder_path <- paste0("models/", nameLLM, "-", text_set, "-", train_size)
save_model <- TRUE
save_embeddings <- TRUE
save_predictions <- TRUE
save_contributions <- TRUE
force_rerun <- FALSE
```

# Save to file
```{r save matrix, echo=TRUE}
save <- function(values, dir, fileName) {
  if (!dir.exists(file.path(dir))) {
    dir.create(file.path(dir))
  }
  saveRDS(values, paste0(dir, "/", fileName))
}

```


# Create embeddings
```{r train, echo=TRUE}
if(!file.exists(paste0(embeddings_folder_path, "/embeddings.rds")) || force_rerun){

  embed <- createEmbeddings(
                      data[(test_size+1):data_length, text_set],
                      model=nameLLM,
                      device = "gpu", # cpu, gpu, mps
                      dim_name = FALSE, # For prediction of new texts, this param must be FALSE,
                      trust_remote_code = TRUE,
  )
  if (save_embeddings) {
    save(embed, embeddings_folder_path, "/embeddings.rds")
  }

} else {
  embed <- readRDS(paste0(embeddings_folder_path, "/embeddings.rds"))
}
```

# Train Model / Load Model
```{r train, echo=TRUE}
if(!file.exists(paste0(model_folder_path, "/models.rds")) || force_rerun) {
### FIX; TODO;
  theModels <- trainLanguageModel(
    x = embed, # embedding
                        y = data[(test_size+1):data_length, scale_total], # scale values, target
                        modelName = nameLLM,
                        mixture = 0
  )

  if (save_model) {
    save(theModels, model_folder_path, "/models.rds")
  }

} else {
  theModels <- readRDS(paste0(model_folder_path, "/models.rds"))
}
```

# Predict and plot
```{r pred and plot, echo=TRUE}
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding=localeToCharset()
)
paragraphs_to_plot <- 1:test_size
evaluation_folder_path <- paste0("models/", nameLLM, "-", text_set, "-test_set-", test_size)
if(!file.exists(paste0(evaluation_folder_path, "/embeddings.rds")) || force_rerun) {

  testEmbed <- createEmbeddings(data[paragraphs_to_plot, text_set],
                          model=nameLLM,
                          dim_name=FALSE,
                          device="gpu",
                          trust_remote_code = TRUE)


  if (save_embeddings) {
    save(testEmbed, evaluation_folder_path, "/embeddings.rds")
  }
} else {
  testEmbed <- readRDS(paste0(evaluation_folder_path, "/embeddings.rds"))
}
```

```{r}
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding=localeToCharset()
)

if (!file.exists(paste0(evaluation_folder_path, "/predictions.rds")) || force_rerun ) {
  predictions <- predictLanguage(testEmbed, theModels$paragraphModel)

  if (save_predictions) {
    saveRDS(predictions, evaluation_folder_path, "/predictions.rds")
  }
} else {
  predictions <- readRDS(paste0(evaluation_folder_path, "/predictions.rds"))
}
```

```{r}
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding=localeToCharset()
)
save_contributions <- TRUE
referenceValue <- theModels$paragraphModel$final_model$fit$fit$fit$a0[[1]]
contributions_file <- paste0("/contributions-ref_", referenceValue, ".rds")

if (!file.exists(paste0(evaluation_folder_path, contributions_file)) || force_rerun) {

  contributions <- getContributionScores(predictions, theModels$paragraphModel, nameLLM, referenceValue, FALSE)

  if (save_contributions) {
    saveRDS(contributions, evaluation_folder_path, contributions_file)
  }
} else {
  contributions <- readRDS(paste0(evaluation_folder_path, contributions_file))
}

```

```{r}
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding=localeToCharset()
)
save_contributions <- TRUE
referenceValue <- theModels$paragraphModel$final_model$fit$fit$fit$a0[[1]]
general_contributions_file <- paste0("/general_contributions-ref_", referenceValue, ".rds")

if (!file.exists(paste0(evaluation_folder_path, general_contributions_file)) || force_rerun ) {

  general_contributions <- getContributionScores(predictions, theModels$paragraphModel, nameLLM, referenceValue, TRUE)

  if (save_contributions) {
    saveRDS(general_contributions, evaluation_folder_path, general_contributions_file)
  }
} else {
  general_contributions <- readRDS(paste0(evaluation_folder_path, general_contributions_file))
}

```

# Pearson Correlation
```{r}
print("Pearson correlation: ")
print(pearsonCorrelation(predictions$paragraphs$predicted_value, data[paragraphs_to_plot,scale_total]))
```
```{r}
source(
  "paragraph_viz_v2.R", # plotting functions
  encoding=localeToCharset()
)
plot <- generateDocument(contributions, data[paragraphs_to_plot, scale_total], limits = c(0, 27), shapley = TRUE, filePath = paste0(model_folder_path, "/plot_paragraphs_", paragraphs_to_plot[1], "-", paragraphs_to_plot[length(paragraphs_to_plot)], "-shapley",".html"))
plot
```

```{r}
#Only here so we can run above
```